{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJqZ76rJh2rM",
    "outputId": "c7648628-a72f-467b-bca4-b7fb003885fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project ID is: gen-lang-client-0303567819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your active configuration is: [personal]\n"
     ]
    }
   ],
   "source": [
    "# Define project information\n",
    "\n",
    "import sys\n",
    "\n",
    "PROJECT_ID = \"gen-lang-client-0303567819\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# if not running on colab, try to get the PROJECT_ID automatically\n",
    "if \"google.colab\" not in sys.modules:\n",
    "    import subprocess\n",
    "\n",
    "    PROJECT_ID = subprocess.check_output(\n",
    "        [\"gcloud\", \"config\", \"get-value\", \"project\"], text=True\n",
    "    ).strip()\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "D48gUW5-h2rM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "rtMowvm-yQ97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rich import print as rich_print\n",
    "from rich.markdown import Markdown as rich_Markdown\n",
    "from IPython.display import Markdown, display\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.vision_models import MultiModalEmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "SvMwSRJJh2rM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luizeng/Documents/fanshawe_repo/test-image-text-gemini/.venv/lib/python3.13/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "# Multimodal models: Choose based on your performance/cost needs\n",
    "\n",
    "multimodal_model_2_0_flash = GenerativeModel(\n",
    "    \"gemini-2.0-flash-001\"\n",
    ") # Gemini latest Gemini 2.0 Flash Model\n",
    "\n",
    "multimodal_model_15 = GenerativeModel(\n",
    "    \"gemini-1.5-pro-001\"\n",
    ")  # works with text, code, images, video(with or without audio) and audio(mp3) with 1M input context - complex reasoning\n",
    "\n",
    "# Multimodal models: Choose based on your performance/cost needs\n",
    "multimodal_model_15_flash = GenerativeModel(\n",
    "    \"gemini-1.5-flash-001\"\n",
    ")  # works with text, code, images, video(with or without audio) and audio(mp3) with 1M input context - faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luizeng/Documents/fanshawe_repo/test-image-text-gemini/.venv/lib/python3.13/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "E0000 00:00:1762622587.834846   55913 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Load text embedding model from pre-trained source\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1762622599.768168   55913 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "multimodal_embedding_model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multimodal_qa_with_rag_utils import (\n",
    "    get_document_metadata,\n",
    "    set_global_variable,\n",
    ")\n",
    "\n",
    "set_global_variable(\"text_embedding_model\", text_embedding_model)\n",
    "set_global_variable(\"multimodal_embedding_model\", multimodal_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 78 (OPCIONAL) - üìÑ EXTRAIR MAIS IMAGENS DO PDF PARA COMPARA√á√ÉO\n",
    "# Esta c√©lula extrai imagens do map.pdf para ter mais dados para compara√ß√£o\n",
    "\n",
    "# === EXTRAINDO IMAGENS DO PDF PARA AMPLIAR DATASET ===\n",
    "#\n",
    "# Esta c√©lula verifica se h√° m√∫ltiplas imagens na pasta \"images/\".\n",
    "# Se houver uma √∫nica imagem ou nenhuma, tenta extrair imagens do \"map/map.pdf\" (se existir).\n",
    "# Caso n√£o encontre o PDF padr√£o, procura outros arquivos PDF na √°rvore de diret√≥rios do projeto,\n",
    "# extrai imagens do primeiro encontrado e as salva em \"images/\".\n",
    "# Ao final, imprime orienta√ß√µes para o usu√°rio sobre os pr√≥ximos passos.\n",
    "\n",
    "#import os\n",
    "#import fitz  # PyMuPDF\n",
    "#\n",
    "#def extrair_imagens_do_pdf(pdf_path, output_dir=\"images/\", prefixo=\"map\"):\n",
    "#    \"\"\"\n",
    "#    Extrai imagens de um PDF e salva na pasta de imagens.\n",
    "#    Args:\n",
    "#        pdf_path (str): caminho do PDF de origem.\n",
    "#        output_dir (str): pasta para salvar as imagens extra√≠das.\n",
    "#        prefixo (str): prefixo opcional para nomear os arquivos de sa√≠da.\n",
    "#    Returns:\n",
    "#        list: caminhos das imagens extra√≠das.\n",
    "#    \"\"\"\n",
    "#    print(f\"üîç Processando PDF: {pdf_path}\")\n",
    "#    \n",
    "#    if not os.path.exists(pdf_path):\n",
    "#        print(f\"‚ùå PDF n√£o encontrado: {pdf_path}\")\n",
    "#        return []\n",
    "#    \n",
    "#    os.makedirs(output_dir, exist_ok=True)\n",
    "#    doc = fitz.open(pdf_path)\n",
    "#    imagens_extraidas = []\n",
    "#    \n",
    "#    print(f\"üìä PDF tem {len(doc)} p√°ginas\")\n",
    "#    \n",
    "#    for page_num in range(len(doc)):\n",
    "#        page = doc[page_num]\n",
    "#        images = page.get_images()\n",
    "#        print(f\"üìÑ P√°gina {page_num + 1}: {len(images)} imagens encontradas\")\n",
    "#        \n",
    "#        for img_index, img in enumerate(images):\n",
    "#            try:\n",
    "#                xref = img[0]\n",
    "#                pix = fitz.Pixmap(doc, xref)\n",
    "#                if pix.colorspace and pix.colorspace.n > 3:\n",
    "#                    pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "#                img_filename = f\"{prefixo}_page_{page_num + 1}_img_{img_index + 1}.png\"\n",
    "#                img_path = os.path.join(output_dir, img_filename)\n",
    "#                pix.save(img_path)\n",
    "#                imagens_extraidas.append(img_path)\n",
    "#                print(f\"  ‚úÖ Extra√≠da: {img_filename}\")\n",
    "#                pix = None  # Libera mem√≥ria\n",
    "#            except Exception as e:\n",
    "#                print(f\"  ‚ùå Erro ao extrair imagem {img_index}: {e}\")\n",
    "#                continue\n",
    "#    \n",
    "#    doc.close()\n",
    "#    print(f\"\\nüéâ Total de {len(imagens_extraidas)} imagens extra√≠das!\")\n",
    "#    return imagens_extraidas\n",
    "#\n",
    "## Conta as imagens j√° presentes na pasta\n",
    "#current_images = len([f for f in os.listdir(\"images/\") if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "#print(f\"üìä Imagens atuais na pasta: {current_images}\")\n",
    "#\n",
    "#if current_images <= 1:\n",
    "#    print(\"üîÑ Extraindo imagens do PDF para ter mais dados...\")\n",
    "#    # Tenta extrair do arquivo padr√£o\n",
    "#    if os.path.exists(\"map/map.pdf\"):\n",
    "#        imagens_extraidas = extrair_imagens_do_pdf(\"map/map.pdf\", \"images/\", \"map\")\n",
    "#        if imagens_extraidas:\n",
    "#            print(f\"\\n‚úÖ {len(imagens_extraidas)} novas imagens adicionadas!\")\n",
    "#            print(\"üöÄ Agora execute a C√âLULA 76 novamente para processar todas as imagens\")\n",
    "#            print(\"   Depois execute a C√âLULA 70 para testar similaridade com mais dados\")\n",
    "#        else:\n",
    "#            print(\"‚ùå Nenhuma imagem foi extra√≠da do PDF\")\n",
    "#    else:\n",
    "#        print(\"‚ùå Arquivo map/map.pdf n√£o encontrado\")\n",
    "#        \n",
    "#        # Verificar outros PDFs dispon√≠veis\n",
    "#        print(\"\\nüîç Procurando outros PDFs...\")\n",
    "#        pdf_paths = []\n",
    "#        for root, dirs, files in os.walk(\".\"):\n",
    "#            for file in files:\n",
    "#                if file.lower().endswith('.pdf'):\n",
    "#                    pdf_paths.append(os.path.join(root, file))\n",
    "#        \n",
    "#        if pdf_paths:\n",
    "#            print(\"üìã PDFs encontrados:\")\n",
    "#            for i, pdf_path in enumerate(pdf_paths[:3], 1):  # Mostrar apenas os 3 primeiros\n",
    "#                print(f\"  {i}. {pdf_path}\")\n",
    "#                \n",
    "#            # Processar o primeiro PDF encontrado\n",
    "#            if pdf_paths:\n",
    "#                primeiro_pdf = pdf_paths[0]\n",
    "#                print(f\"\\nüîÑ Processando: {primeiro_pdf}\")\n",
    "#                imagens_extraidas = extrair_imagens_do_pdf(primeiro_pdf, \"images/\", \"doc\")\n",
    "#                \n",
    "#                if imagens_extraidas:\n",
    "#                    print(f\"\\n‚úÖ {len(imagens_extraidas)} imagens extra√≠das de {primeiro_pdf}!\")\n",
    "#                    print(\"üöÄ Execute a C√âLULA 76 novamente para processar todas as imagens\")\n",
    "#        else:\n",
    "#            print(\"‚ùå Nenhum PDF encontrado para extrair imagens\")\n",
    "#            \n",
    "#else:\n",
    "#    print(\"‚úÖ J√° h√° m√∫ltiplas imagens na pasta\")\n",
    "#    print(\"Execute a C√âLULA 76 para processar todas e depois a C√âLULA 70 para testar similaridade\")\n",
    "#\n",
    "## Mostrar status final\n",
    "#final_images = len([f for f in os.listdir(\"images/\") if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "#print(f\"\\nüìä STATUS FINAL: {final_images} imagens na pasta 'images/'\")\n",
    "#\n",
    "#if final_images > 1:\n",
    "#    print(\"üéâ Pronto para testar busca por similaridade!\")\n",
    "#    print(\"üìã PR√ìXIMOS PASSOS:\")\n",
    "#    print(\"  1. Execute C√âLULA 76 (processar todas as imagens)\")\n",
    "#    print(\"  2. Execute C√âLULA 70 (busca por similaridade)\")\n",
    "#    print(\"  3. Execute C√âLULA 71 (an√°lise contextual)\")\n",
    "#else:\n",
    "#    print(\"‚ö†Ô∏è  Ainda h√° apenas 1 imagem. Adicione mais imagens manualmente na pasta 'images/'\")\n",
    "#else:\n",
    "#    print(\"‚ö†Ô∏è  Ainda h√° apenas 1 imagem. Adicione mais imagens manualmente na pasta 'images/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fun√ß√£o 'processar_imagens_da_pasta' criada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# C√âLULA 75 (NOVO) - üìÇ PROCESSAMENTO DIRETO DE IMAGENS DA PASTA\n",
    "# Fun√ß√£o para ler todas as imagens da pasta images/ e gerar embeddings para RAG\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from vertexai.generative_models import Image as GeminiImage, GenerationConfig, HarmCategory, HarmBlockThreshold\n",
    "from multimodal_qa_with_rag_utils import (\n",
    "    get_image_embedding_from_multimodal_embedding_model,\n",
    ")\n",
    "\n",
    "def processar_imagens_da_pasta(\n",
    "    pasta_imagens=\"images/\",\n",
    "    embedding_size=512,\n",
    "    gerar_descricoes=True,\n",
    "    formatos_suportados=['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "):\n",
    "    \"\"\"\n",
    "    Processa todas as imagens de uma pasta, gerando embeddings e descri√ß√µes para RAG\n",
    "    \n",
    "    Args:\n",
    "        pasta_imagens: Caminho da pasta com imagens\n",
    "        embedding_size: Tamanho do embedding (128, 256, 512, 1408)\n",
    "        gerar_descricoes: Se deve gerar descri√ß√µes das imagens com Gemini\n",
    "        formatos_suportados: Lista de formatos de imagem aceitos\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame compat√≠vel com o sistema RAG existente\n",
    "    \"\"\"\n",
    "    print(f\"üîç PROCESSANDO IMAGENS DA PASTA: {pasta_imagens}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Verificar se a pasta existe\n",
    "    if not os.path.exists(pasta_imagens):\n",
    "        print(f\"‚ùå Pasta '{pasta_imagens}' n√£o encontrada!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Encontrar todas as imagens na pasta\n",
    "    imagens_encontradas = []\n",
    "    for formato in formatos_suportados:\n",
    "        pattern = os.path.join(pasta_imagens, f\"*{formato}\")\n",
    "        imagens_encontradas.extend(glob.glob(pattern))\n",
    "        pattern = os.path.join(pasta_imagens, f\"*{formato.upper()}\")\n",
    "        imagens_encontradas.extend(glob.glob(pattern))\n",
    "    \n",
    "    # Remover duplicatas\n",
    "    imagens_encontradas = list(set(imagens_encontradas))\n",
    "    \n",
    "    if not imagens_encontradas:\n",
    "        print(f\"‚ùå Nenhuma imagem encontrada na pasta '{pasta_imagens}'\")\n",
    "        print(f\"Formatos suportados: {formatos_suportados}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"üìä Encontradas {len(imagens_encontradas)} imagens:\")\n",
    "    for img in imagens_encontradas:\n",
    "        print(f\"  - {os.path.basename(img)}\")\n",
    "    \n",
    "    # Lista para armazenar dados processados\n",
    "    dados_imagens = []\n",
    "    \n",
    "    # Prompt para descri√ß√£o das imagens\n",
    "    prompt_descricao = \"\"\"Analise esta imagem detalhadamente e forne√ßa uma descri√ß√£o precisa.\n",
    "    Inclua:\n",
    "    - O que voc√™ v√™ na imagem\n",
    "    - Elementos principais e detalhes importantes\n",
    "    - Texto vis√≠vel (se houver)\n",
    "    - Tipo de imagem (mapa, diagrama, foto, etc.)\n",
    "    - Informa√ß√µes relevantes para busca e recupera√ß√£o\n",
    "    \n",
    "    Seja espec√≠fico e detalhado para facilitar buscas futuras.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüöÄ PROCESSANDO CADA IMAGEM...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Configure generation parameters\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=2048\n",
    "    )\n",
    "            \n",
    "    safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    }\n",
    "    \n",
    "    for i, caminho_imagem in enumerate(imagens_encontradas, 1):\n",
    "        nome_arquivo = os.path.basename(caminho_imagem)\n",
    "        print(f\"\\nüì∏ PROCESSANDO {i}/{len(imagens_encontradas)}: {nome_arquivo}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Gerar embedding da imagem\n",
    "            print(\"  üîÑ Gerando embedding...\")\n",
    "            image_embedding = get_image_embedding_from_multimodal_embedding_model(\n",
    "                image_uri=caminho_imagem,\n",
    "                embedding_size=embedding_size,\n",
    "                return_array=True\n",
    "            )\n",
    "            print(f\"  ‚úÖ Embedding gerado: shape {image_embedding.shape}\")\n",
    "            \n",
    "            # 2. Gerar descri√ß√£o da imagem (se solicitado)\n",
    "            descricao = \"\"\n",
    "            if gerar_descricoes:\n",
    "                print(\"  ü§ñ Gerando descri√ß√£o com Gemini...\")\n",
    "                try:\n",
    "                    imagem_gemini = GeminiImage.load_from_file(caminho_imagem)\n",
    "                    \n",
    "                    response = multimodal_model_2_0_flash.generate_content(\n",
    "                        [prompt_descricao, imagem_gemini],\n",
    "                        generation_config=generation_config,\n",
    "                        safety_settings=safety_settings\n",
    "                    )\n",
    "                    \n",
    "                    if response and response.text:\n",
    "                        descricao = response.text\n",
    "                        print(f\"  ‚úÖ Descri√ß√£o gerada: {len(descricao)} caracteres\")\n",
    "                    else:\n",
    "                        print(\"  ‚ö†Ô∏è  Sem resposta do modelo\")\n",
    "                        descricao = f\"Imagem: {nome_arquivo}\"\n",
    "                    \n",
    "                except Exception as desc_error:\n",
    "                    print(f\"  ‚ö†Ô∏è  Erro ao gerar descri√ß√£o: {desc_error}\")\n",
    "                    descricao = f\"Imagem: {nome_arquivo}\"\n",
    "            \n",
    "            # 3. Gerar embedding da descri√ß√£o (para compatibilidade com RAG)\n",
    "            text_embedding = None\n",
    "            if descricao:\n",
    "                try:\n",
    "                    from multimodal_qa_with_rag_utils import get_text_embedding_from_text_embedding_model\n",
    "                    text_embedding = get_text_embedding_from_text_embedding_model(descricao)\n",
    "                    print(\"  ‚úÖ Text embedding da descri√ß√£o gerado\")\n",
    "                except Exception as text_emb_error:\n",
    "                    print(f\"  ‚ö†Ô∏è  Erro ao gerar text embedding: {text_emb_error}\")\n",
    "            \n",
    "            # 4. Criar registro compat√≠vel com o sistema existente\n",
    "            registro = {\n",
    "                'file_name': f\"pasta_images_{nome_arquivo}\",  # Nome √∫nico\n",
    "                'page_num': 1,  # Imagens individuais = p√°gina 1\n",
    "                'img_num': i,\n",
    "                'img_path': caminho_imagem,\n",
    "                'img_desc': descricao,\n",
    "                'mm_embedding_from_img_only': image_embedding.tolist(),  # Compatibilidade\n",
    "                'text_embedding_from_image_description': text_embedding if text_embedding else None,\n",
    "                'source_type': 'pasta_imagens',  # Identificar origem\n",
    "                'original_filename': nome_arquivo\n",
    "            }\n",
    "            \n",
    "            dados_imagens.append(registro)\n",
    "            print(f\"  ‚úÖ Processamento conclu√≠do para {nome_arquivo}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erro ao processar {nome_arquivo}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    if dados_imagens:\n",
    "        df_imagens = pd.DataFrame(dados_imagens)\n",
    "        print(f\"\\nüéâ PROCESSAMENTO CONCLU√çDO!\")\n",
    "        print(f\"üìä DataFrame criado com {len(df_imagens)} imagens processadas\")\n",
    "        print(f\"üìã Colunas: {list(df_imagens.columns)}\")\n",
    "        \n",
    "        return df_imagens\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Nenhuma imagem foi processada com sucesso\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o 'processar_imagens_da_pasta' criada com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROCESSAMENTO COMPLETO DA PASTA IMAGES/ ===\n",
      "\n",
      "üîç PROCESSANDO IMAGENS DA PASTA: images/\n",
      "============================================================\n",
      "üìä Encontradas 2 imagens:\n",
      "  - A1.png\n",
      "  - B2_room.jpeg\n",
      "\n",
      "üöÄ PROCESSANDO CADA IMAGEM...\n",
      "============================================================\n",
      "\n",
      "üì∏ PROCESSANDO 1/2: A1.png\n",
      "  üîÑ Gerando embedding...\n",
      "  ‚úÖ Embedding gerado: shape (512,)\n",
      "  ü§ñ Gerando descri√ß√£o com Gemini...\n",
      "  ‚úÖ Embedding gerado: shape (512,)\n",
      "  ü§ñ Gerando descri√ß√£o com Gemini...\n",
      "  ‚úÖ Descri√ß√£o gerada: 2683 caracteres\n",
      "  ‚úÖ Descri√ß√£o gerada: 2683 caracteres\n",
      "  ‚úÖ Text embedding da descri√ß√£o gerado\n",
      "  ‚úÖ Processamento conclu√≠do para A1.png\n",
      "\n",
      "üì∏ PROCESSANDO 2/2: B2_room.jpeg\n",
      "  üîÑ Gerando embedding...\n",
      "  ‚úÖ Text embedding da descri√ß√£o gerado\n",
      "  ‚úÖ Processamento conclu√≠do para A1.png\n",
      "\n",
      "üì∏ PROCESSANDO 2/2: B2_room.jpeg\n",
      "  üîÑ Gerando embedding...\n",
      "  ‚úÖ Embedding gerado: shape (512,)\n",
      "  ü§ñ Gerando descri√ß√£o com Gemini...\n",
      "  ‚úÖ Embedding gerado: shape (512,)\n",
      "  ü§ñ Gerando descri√ß√£o com Gemini...\n",
      "  ‚úÖ Descri√ß√£o gerada: 2478 caracteres\n",
      "  ‚úÖ Descri√ß√£o gerada: 2478 caracteres\n",
      "  ‚úÖ Text embedding da descri√ß√£o gerado\n",
      "  ‚úÖ Processamento conclu√≠do para B2_room.jpeg\n",
      "\n",
      "üéâ PROCESSAMENTO CONCLU√çDO!\n",
      "üìä DataFrame criado com 2 imagens processadas\n",
      "üìã Colunas: ['file_name', 'page_num', 'img_num', 'img_path', 'img_desc', 'mm_embedding_from_img_only', 'text_embedding_from_image_description', 'source_type', 'original_filename']\n",
      "\n",
      "üéâ SUCESSO TOTAL!\n",
      "üìä image_metadata_df criado com 2 imagens\n",
      "\n",
      "üìã RESUMO DAS IMAGENS PROCESSADAS:\n",
      "==================================================\n",
      "\n",
      "üñºÔ∏è  Imagem 1:\n",
      "  üìÅ Arquivo: A1.png\n",
      "  üìÇ Caminho: images/A1.png\n",
      "  üìä Embedding shape: 512\n",
      "  üìù Descri√ß√£o: Aqui est√° uma descri√ß√£o detalhada da imagem:\n",
      "\n",
      "**O que voc√™ v√™ na imagem:**\n",
      "\n",
      "A imagem √© uma planta baixa de um edif√≠cio, especificamente o primeiro and...\n",
      "\n",
      "üñºÔ∏è  Imagem 2:\n",
      "  üìÅ Arquivo: B2_room.jpeg\n",
      "  üìÇ Caminho: images/B2_room.jpeg\n",
      "  üìä Embedding shape: 512\n",
      "  üìù Descri√ß√£o: Here's a detailed description of the image:\n",
      "\n",
      "**What I see:**\n",
      "\n",
      "The image is a photograph of a floor plan directory sign. The sign displays a map of \"Fl...\n",
      "\n",
      "‚úÖ COMPATIBILIDADE COM SISTEMA RAG:\n",
      "  ‚úÖ img_path: OK\n",
      "  ‚úÖ mm_embedding_from_img_only: OK\n",
      "  ‚úÖ img_desc: OK\n",
      "  ‚úÖ file_name: OK\n",
      "  ‚úÖ page_num: OK\n",
      "\n",
      "üíæ DataFrame salvo em 'image_metadata_from_folder.pkl'\n",
      "\n",
      "üöÄ PR√ìXIMOS PASSOS:\n",
      "1. Agora voc√™ pode executar a C√âLULA 70 (Valida√ß√£o)\n",
      "2. Depois executar a C√âLULA 71 (An√°lise Contextual)\n",
      "3. O sistema RAG est√° pronto para perguntas sobre as imagens!\n",
      "  ‚úÖ Text embedding da descri√ß√£o gerado\n",
      "  ‚úÖ Processamento conclu√≠do para B2_room.jpeg\n",
      "\n",
      "üéâ PROCESSAMENTO CONCLU√çDO!\n",
      "üìä DataFrame criado com 2 imagens processadas\n",
      "üìã Colunas: ['file_name', 'page_num', 'img_num', 'img_path', 'img_desc', 'mm_embedding_from_img_only', 'text_embedding_from_image_description', 'source_type', 'original_filename']\n",
      "\n",
      "üéâ SUCESSO TOTAL!\n",
      "üìä image_metadata_df criado com 2 imagens\n",
      "\n",
      "üìã RESUMO DAS IMAGENS PROCESSADAS:\n",
      "==================================================\n",
      "\n",
      "üñºÔ∏è  Imagem 1:\n",
      "  üìÅ Arquivo: A1.png\n",
      "  üìÇ Caminho: images/A1.png\n",
      "  üìä Embedding shape: 512\n",
      "  üìù Descri√ß√£o: Aqui est√° uma descri√ß√£o detalhada da imagem:\n",
      "\n",
      "**O que voc√™ v√™ na imagem:**\n",
      "\n",
      "A imagem √© uma planta baixa de um edif√≠cio, especificamente o primeiro and...\n",
      "\n",
      "üñºÔ∏è  Imagem 2:\n",
      "  üìÅ Arquivo: B2_room.jpeg\n",
      "  üìÇ Caminho: images/B2_room.jpeg\n",
      "  üìä Embedding shape: 512\n",
      "  üìù Descri√ß√£o: Here's a detailed description of the image:\n",
      "\n",
      "**What I see:**\n",
      "\n",
      "The image is a photograph of a floor plan directory sign. The sign displays a map of \"Fl...\n",
      "\n",
      "‚úÖ COMPATIBILIDADE COM SISTEMA RAG:\n",
      "  ‚úÖ img_path: OK\n",
      "  ‚úÖ mm_embedding_from_img_only: OK\n",
      "  ‚úÖ img_desc: OK\n",
      "  ‚úÖ file_name: OK\n",
      "  ‚úÖ page_num: OK\n",
      "\n",
      "üíæ DataFrame salvo em 'image_metadata_from_folder.pkl'\n",
      "\n",
      "üöÄ PR√ìXIMOS PASSOS:\n",
      "1. Agora voc√™ pode executar a C√âLULA 70 (Valida√ß√£o)\n",
      "2. Depois executar a C√âLULA 71 (An√°lise Contextual)\n",
      "3. O sistema RAG est√° pronto para perguntas sobre as imagens!\n"
     ]
    }
   ],
   "source": [
    "# C√âLULA 76 (EXECUTAR) - üöÄ PROCESSAMENTO DAS IMAGENS DA PASTA images/\n",
    "# Executa o processamento de todas as imagens e cria o image_metadata_df\n",
    "\n",
    "print(\"=== PROCESSAMENTO COMPLETO DA PASTA IMAGES/ ===\\n\")\n",
    "\n",
    "# Executar o processamento das imagens\n",
    "try:\n",
    "    image_metadata_df = processar_imagens_da_pasta(\n",
    "        pasta_imagens=\"images/\",\n",
    "        embedding_size=512,\n",
    "        gerar_descricoes=True,  # Gerar descri√ß√µes detalhadas com Gemini\n",
    "        formatos_suportados=['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "    )\n",
    "    \n",
    "    if not image_metadata_df.empty:\n",
    "        print(f\"\\nüéâ SUCESSO TOTAL!\")\n",
    "        print(f\"üìä image_metadata_df criado com {len(image_metadata_df)} imagens\")\n",
    "        \n",
    "        # Mostrar resumo das imagens processadas\n",
    "        print(f\"\\nüìã RESUMO DAS IMAGENS PROCESSADAS:\")\n",
    "        print(\"=\"*50)\n",
    "        for idx, row in image_metadata_df.iterrows():\n",
    "            print(f\"\\nüñºÔ∏è  Imagem {idx + 1}:\")\n",
    "            print(f\"  üìÅ Arquivo: {row['original_filename']}\")\n",
    "            print(f\"  üìÇ Caminho: {row['img_path']}\")\n",
    "            print(f\"  üìä Embedding shape: {len(row['mm_embedding_from_img_only'])}\")\n",
    "            \n",
    "            # Mostrar in√≠cio da descri√ß√£o\n",
    "            desc = row['img_desc']\n",
    "            if desc and len(desc) > 10:\n",
    "                print(f\"  üìù Descri√ß√£o: {desc[:150]}{'...' if len(desc) > 150 else ''}\")\n",
    "        \n",
    "        # Verificar compatibilidade com sistema RAG existente\n",
    "        print(f\"\\n‚úÖ COMPATIBILIDADE COM SISTEMA RAG:\")\n",
    "        colunas_necessarias = ['img_path', 'mm_embedding_from_img_only', 'img_desc', 'file_name', 'page_num']\n",
    "        for col in colunas_necessarias:\n",
    "            if col in image_metadata_df.columns:\n",
    "                print(f\"  ‚úÖ {col}: OK\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {col}: FALTANDO\")\n",
    "        \n",
    "        # Salvar para uso futuro (opcional)\n",
    "        try:\n",
    "            image_metadata_df.to_pickle(\"image_metadata_from_folder.pkl\")\n",
    "            print(f\"\\nüíæ DataFrame salvo em 'image_metadata_from_folder.pkl'\")\n",
    "        except Exception as save_error:\n",
    "            print(f\"\\n‚ö†Ô∏è  N√£o foi poss√≠vel salvar: {save_error}\")\n",
    "        \n",
    "        print(f\"\\nüöÄ PR√ìXIMOS PASSOS:\")\n",
    "        print(f\"1. Agora voc√™ pode executar a C√âLULA 70 (Valida√ß√£o)\")\n",
    "        print(f\"2. Depois executar a C√âLULA 71 (An√°lise Contextual)\")\n",
    "        print(f\"3. O sistema RAG est√° pronto para perguntas sobre as imagens!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå FALHA: Nenhuma imagem foi processada\")\n",
    "        print(f\"Verifique se:\")\n",
    "        print(f\"- A pasta 'images/' existe\")\n",
    "        print(f\"- H√° imagens v√°lidas na pasta\")\n",
    "        print(f\"- Os modelos est√£o carregados corretamente\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO NO PROCESSAMENTO: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\nüí° POSS√çVEIS SOLU√á√ïES:\")\n",
    "    print(f\"- Verifique se os modelos est√£o carregados\")\n",
    "    print(f\"- Verifique se a pasta 'images/' existe\")\n",
    "    print(f\"- Execute as c√©lulas de setup dos modelos primeiro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import Image as GeminiImage, GenerationConfig, HarmCategory, HarmBlockThreshold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def chat_about_images(question, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Chat about images using embedding similarity and Gemini model\n",
    "    \n",
    "    Args:\n",
    "        question (str): User's question about the images\n",
    "        threshold (float): Similarity threshold for image matching\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get text embedding for the question\n",
    "        question_embeddings = text_embedding_model.get_embeddings([question])\n",
    "        question_embedding = np.array(question_embeddings[0].values)\n",
    "        \n",
    "        # Calculate similarities with all images\n",
    "        similarities = []\n",
    "        for _, row in image_metadata_df.iterrows():\n",
    "            try:\n",
    "                # Use text embedding's description embedding for comparison\n",
    "                # since we can't resize the embeddings easily\n",
    "                if row['text_embedding_from_image_description'] is not None:\n",
    "                    compare_embedding = np.array(row['text_embedding_from_image_description'])\n",
    "                    \n",
    "                    # Normalize vectors for cosine similarity\n",
    "                    norm_question = np.linalg.norm(question_embedding)\n",
    "                    norm_compare = np.linalg.norm(compare_embedding)\n",
    "                    \n",
    "                    if norm_question == 0 or norm_compare == 0:\n",
    "                        similarity = 0\n",
    "                    else:\n",
    "                        # Calculate cosine similarity\n",
    "                        similarity = np.dot(question_embedding, compare_embedding) / (norm_question * norm_compare)\n",
    "                    \n",
    "                    similarities.append({\n",
    "                        'img_path': row['img_path'],\n",
    "                        'img_desc': row['img_desc'],\n",
    "                        'similarity': float(similarity)  # Convert to native Python float\n",
    "                    })\n",
    "            except Exception as row_error:\n",
    "                continue\n",
    "        \n",
    "        if not similarities:\n",
    "            print(\"I could not find any relevant information to answer your question.\")\n",
    "            return\n",
    "            \n",
    "        # Sort by similarity\n",
    "        similarities = sorted(similarities, key=lambda x: x['similarity'], reverse=True)\n",
    "        \n",
    "        # Get most relevant image\n",
    "        best_match = similarities[0]\n",
    "        \n",
    "        if best_match['similarity'] < threshold:\n",
    "            print(\"I could not find any relevant information to answer your question.\")\n",
    "            return\n",
    "        \n",
    "        # Generate response using Gemini\n",
    "        try:\n",
    "            image = GeminiImage.load_from_file(best_match['img_path'])\n",
    "            \n",
    "            # Configure generation parameters\n",
    "            generation_config = GenerationConfig(\n",
    "                temperature=0.2,\n",
    "                max_output_tokens=2048\n",
    "            )\n",
    "            \n",
    "            safety_settings = {\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "            \n",
    "            prompt = f\"\"\"Question: {question}\n",
    "            Image description: {best_match['img_desc']}\n",
    "            \n",
    "            Analyze the image and provide a clear, detailed answer to the question. If you cannot determine the answer from the image, say so.\"\"\"\n",
    "            \n",
    "            response = multimodal_model_2_0_flash.generate_content(\n",
    "                [prompt, image],\n",
    "                generation_config=generation_config,\n",
    "                safety_settings=safety_settings\n",
    "            )\n",
    "            \n",
    "            if response and response.text:\n",
    "                print(response.text)\n",
    "            else:\n",
    "                print(\"I apologize, but I could not generate an answer based on the available information.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"I apologize, but I could not generate an answer based on the available information.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"I apologize, but I encountered an error while processing your question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What appears in room B2?\n",
      "Based on the image of the floor plan directory, room B2 does not exist. The directory is for \"B2 Orange\" on \"Floor 1\". The floor plan shows rooms numbered in the 2000s (e.g., 2001, 2002, 2005, etc.). Therefore, there is no room labeled \"B2\" on this floor plan.\n",
      "\n",
      "\n",
      "How many room has in the map A1?\n",
      "Based on the image of the floor plan directory, room B2 does not exist. The directory is for \"B2 Orange\" on \"Floor 1\". The floor plan shows rooms numbered in the 2000s (e.g., 2001, 2002, 2005, etc.). Therefore, there is no room labeled \"B2\" on this floor plan.\n",
      "\n",
      "\n",
      "How many room has in the map A1?\n",
      "Based on the provided floor plan of the A Building, First Floor, at 1001 Fanshawe College Blvd, the following rooms are identifiable:\n",
      "\n",
      "1.  1001\n",
      "2.  1004\n",
      "3.  1005\n",
      "4.  1006\n",
      "5.  1007\n",
      "6.  1010\n",
      "7.  1012\n",
      "8.  1014\n",
      "9.  1016\n",
      "10. 1017\n",
      "11. 1018\n",
      "12. 1020\n",
      "13. 1033\n",
      "14. 1043\n",
      "15. 1046\n",
      "16. 1049\n",
      "17. 1051\n",
      "18. 1052\n",
      "19. 1054\n",
      "20. 1057\n",
      "21. 1058\n",
      "22. 1059\n",
      "23. 1063\n",
      "24. 1064\n",
      "\n",
      "Therefore, there are **24 rooms** shown on the map A1.\n",
      "\n",
      "How can i go from 1001 room to 1033 room?\n",
      "I could not find any relevant information to answer your question.\n",
      "Based on the provided floor plan of the A Building, First Floor, at 1001 Fanshawe College Blvd, the following rooms are identifiable:\n",
      "\n",
      "1.  1001\n",
      "2.  1004\n",
      "3.  1005\n",
      "4.  1006\n",
      "5.  1007\n",
      "6.  1010\n",
      "7.  1012\n",
      "8.  1014\n",
      "9.  1016\n",
      "10. 1017\n",
      "11. 1018\n",
      "12. 1020\n",
      "13. 1033\n",
      "14. 1043\n",
      "15. 1046\n",
      "16. 1049\n",
      "17. 1051\n",
      "18. 1052\n",
      "19. 1054\n",
      "20. 1057\n",
      "21. 1058\n",
      "22. 1059\n",
      "23. 1063\n",
      "24. 1064\n",
      "\n",
      "Therefore, there are **24 rooms** shown on the map A1.\n",
      "\n",
      "How can i go from 1001 room to 1033 room?\n",
      "I could not find any relevant information to answer your question.\n"
     ]
    }
   ],
   "source": [
    "# Test different types of questions\n",
    "print(\"Question: What appears in room B2?\")\n",
    "chat_about_images(\"What appears in room B2?\")\n",
    "\n",
    "print(\"\\nHow many room has in the map A1?\")\n",
    "chat_about_images(\"How many room has in the map A1?\")\n",
    "\n",
    "print(\"\\nHow can i go from 1001 room to 1033 room?\")\n",
    "chat_about_images(\"How can i go from 1004 room to 1033 room?\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m116"
  },
  "kernelspec": {
   "display_name": "test-image-text-gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
